{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b13b1e",
   "metadata": {},
   "source": [
    "# Project: Create a Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b981a3",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a11b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c3250",
   "metadata": {},
   "source": [
    "### Step 2: Download stopwords\n",
    "- Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e25497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/rune/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9012c520",
   "metadata": {},
   "source": [
    "### Step 3: Read content and sentinize\n",
    "- Initialize an empty list called **all_sentences**\n",
    "- For each filename in **'files/holmes'**:\n",
    "    - HINT: Use **os.listdir(...)** ([docs](https://docs.python.org/3/library/os.html#os.listdir))\n",
    "- Open the file and read the content and convert to lowercase and apply **nltk.sent_tokenize** on content.\n",
    "    - Use **lower()** on content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8957df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "\n",
    "for filename in os.listdir('files/holmes'):\n",
    "    with open(f'files/holmes/{filename}') as f:\n",
    "        text = f.read().lower()\n",
    "        all_sentences += nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a05a77c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                       the adventure of the speckled band\\n\\n     on glancing over my notes of the seventy odd cases in which i have\\n     during the last eight years studied the methods of my friend sherlock\\n     holmes, i find many tragic, some comic, a large number merely\\n     strange, but none commonplace; for, working as he did rather for the\\n     love of his art than for the acquirement of wealth, he refused to\\n     associate himself with any investigation which did not tend towards\\n     the unusual, and even the fantastic.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4362c",
   "metadata": {},
   "source": [
    "### Step 4: Tokenize each sentence\n",
    "- Get all words by applying **nltk.word_tokenize** on them and assign the result to **all_words**\n",
    "    - HINT: Use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dce4f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'adventure',\n",
       " 'of',\n",
       " 'the',\n",
       " 'speckled',\n",
       " 'band',\n",
       " 'on',\n",
       " 'glancing',\n",
       " 'over',\n",
       " 'my']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "all_words[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959014e8",
   "metadata": {},
   "source": [
    "### Step 5: Remove all stop words\n",
    "- Use **stopwords.words('english')** to filter all the words in **all_words**\n",
    "    - HINT: iterate over the length of **all_words**, for each index use list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6e59b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b865868b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'speckled',\n",
       " 'band',\n",
       " 'glancing',\n",
       " 'notes',\n",
       " 'seventy',\n",
       " 'odd',\n",
       " 'cases',\n",
       " 'last',\n",
       " 'eight']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40656352",
   "metadata": {},
   "source": [
    "### Step 6: Remove special characters\n",
    "- Iterate over items in **all_words** to remove words with special characters\n",
    "    - HINT: Use **isalpha()** ([doc](https://docs.python.org/3/library/stdtypes.html#str.isalpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0590380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fecfa86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'speckled',\n",
       " 'band',\n",
       " 'glancing',\n",
       " 'notes',\n",
       " 'seventy',\n",
       " 'odd',\n",
       " 'cases',\n",
       " 'last',\n",
       " 'eight']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bca8cf",
   "metadata": {},
   "source": [
    "### Step 7: Install gensim and python-Levenshtein\n",
    "- Run the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b43059c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.0.1-cp38-cp38-macosx_10_9_x86_64.whl (23.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.9 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /Users/rune/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/rune/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.0.1 smart-open-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e95bb6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 949 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/rune/opt/anaconda3/lib/python3.8/site-packages (from python-Levenshtein) (52.0.0.post20210125)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp38-cp38-macosx_10_9_x86_64.whl size=80648 sha256=380bc120ef35546e3940410f4e6a75461b9919b2fa6f1ffac9aab52e6dcad8c2\n",
      "  Stored in directory: /Users/rune/Library/Caches/pip/wheels/d7/0c/76/042b46eb0df65c3ccd0338f791210c55ab79d209bcc269e2c7\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein\n",
      "Successfully installed python-Levenshtein-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a94c5",
   "metadata": {},
   "source": [
    "### Step 8: Import another library\n",
    "- Run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8986ec55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dad3d2",
   "metadata": {},
   "source": [
    "### Step 9: Create a model\n",
    "- Use **Word2Vec** on **all_words**\n",
    "    - Use **min_count=2** : Ignores all words with total frequency lower than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8eaae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(all_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da22183",
   "metadata": {},
   "source": [
    "### Step 10: Find distances\n",
    "- Try to run **model.wv.distance('holmes', 'watson')**\n",
    "- Try to run **model.wv.distance('holmes', 'water')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32c60a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000813901424407959"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('holmes', 'watson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "935beeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012812614440917969"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('holmes', 'water')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b26dd8c",
   "metadata": {},
   "source": [
    "### Step 11: Find closests words\n",
    "- Get all the words\n",
    "    - HINT: **words = model.wv.index_to_key**\n",
    "- Implement a function **closets_words(word)**\n",
    "    - HINT: **distances = {w: model.wv.distance(word, w) for w in words}**\n",
    "    - HINT: **sorted(distances, key=lambda w: distances[w])[:15]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f534cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = model.wv.index_to_key\n",
    "\n",
    "def closets_words(word):\n",
    "    distances = {w: model.wv.distance(word, w) for w in words}\n",
    "    return sorted(distances, key=lambda w: distances[w])[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b60d5345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['holmes',\n",
       " 'friend',\n",
       " 'must',\n",
       " 'back',\n",
       " 'come',\n",
       " 'might',\n",
       " 'words',\n",
       " 'quite',\n",
       " 'turned',\n",
       " 'police',\n",
       " 'held',\n",
       " 'watson',\n",
       " 'sat',\n",
       " 'colonel',\n",
       " 'eyes']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closets_words('holmes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49dcfbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
